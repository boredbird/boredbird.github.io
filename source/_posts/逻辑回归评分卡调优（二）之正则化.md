---
title: 逻辑回归评分卡调优（二）之正则化
date: 2017-10-04 13:29:12
categories: "机器学习"
tags:
     - 评分卡
     - 逻辑回归
description: 逻辑回归评分卡调优（二）之正则化
toc: true
---
在[上回](https://boredbird.github.io/2017/10/04/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%84%E5%88%86%E5%8D%A1%E8%B0%83%E4%BC%98%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%9D%E6%8E%A2/)的基础上，可以看出特征之间存在多重共线性，自然的联想到L1正则化，这次主要尝试用sklearn.linear_model中正则化的[LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)去提升模型效果。

``` python

    X = dataset_train[candidate_var_list]
    y = dataset_train['target']

    X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=32)

    from sklearn.linear_model import LogisticRegression
    clf_l1_LR = LogisticRegression(C=0.1, penalty='l1', tol=0.01)


    clf_l1_LR.fit(X_train, y_train)
    proba = clf_l1_LR.predict_proba(X_train)[:,1]
    get_ks(proba,y_train)
    # 0.40141223793092612

    proba = clf_l1_LR.predict_proba(X_test)[:,1]
    get_ks(proba,y_test)
    # 0.39708735770404702
```

可以看出此时采用C=0.1正则化的模型已经有了很大的提升。

``` python

	C : float, default: 1.0

		Inverse of regularization strength; must be a positive float.

		Like in support vector machines, smaller values specify stronger regularization.
```

可是，c是个超参数，如何设置才能达到最优的效果呢？

还是以结果为导向，一个一个试。虽然不是全局最优，那也大差不差。

``` python

    import matplotlib.pyplot as plt
    from datetime import datetime
    from sklearn import linear_model
    from sklearn.svm import l1_min_c
    cs = l1_min_c(X_train, y_train, loss='log') * np.logspace(0, 3)

    print("Computing regularization path ...")
    start = datetime.now()
    print start
    clf_l1_LR = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)
    coefs_ = []
    ks = []
    for c in cs:
    clf_l1_LR.set_params(C=c)
    clf_l1_LR.fit(X_train, y_train)
    coefs_.append(clf_l1_LR.coef_.ravel().copy())

    proba = clf_l1_LR.predict_proba(X_train)[:,1]
    ks.append(get_ks(proba,y_train))

    end = datetime.now()
    print end
    print("This took ", end - start)

    coef_cv_df = pd.DataFrame(coefs_,columns=X_train.columns)
    coef_cv_df.to_csv('E:\\Code\\ScoreCard\\coef_cv_df.csv')

    coefs_ = np.array(coefs_)

    fig1 = plt.figure('fig1')
    plt.plot(np.log10(cs), coefs_)
    ymin, ymax = plt.ylim()
    plt.xlabel('log(C)')
    plt.ylabel('Coefficients')
    plt.title('Logistic Regression Path')
    plt.axis('tight')
    plt.show()

    fig2 = plt.figure('fig2')
    plt.plot(np.log10(cs), ks)
    plt.xlabel('log(C)')
    plt.ylabel('ks score')
    plt.title('Logistic Regression Performance')
    plt.axis('tight')
    plt.show()

    fig2.show()
    fig1.show()
 ```   
