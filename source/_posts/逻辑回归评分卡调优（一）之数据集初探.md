---
title: 逻辑回归评分卡调优（一）之数据集初探
date: 2017-10-04 11:38:12 
categories: "机器学习" 
tags: 
     - 评分卡
     - 逻辑回归
description: 逻辑回归评分卡调优（一）
toc: true
---
本系列记录我在工作中针对同一个数据集，运用逻辑回归（评分卡）模型不断尝试去提升模型ks值表现的过程。并不是范例，更谈不上指导意义。主要是为了记录自己的思考与验证过程，怕随便零散的写在代码注释里过后就忘了。

评分卡模型在数据处理过程中常用到woe转换，这部分的工作我采用了Python的包[woe](https://github.com/boredbird/woe)来完成。

[Woe](https://github.com/boredbird/woe) is a python package containing useful tools for WoE Transformation mostly used in ScoreCard Model for Credit Rating.

[woe](https://github.com/boredbird/woe)包中树节点的分裂方法，是一种Local近似算法。对于每个特征，只考察分位点，减少计算复杂度；每次分裂前，重新提出候选切分点。

关于树节点分裂方法，[这里](https://boredbird.github.io/2017/10/02/GBDT%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E7%AE%80%E4%BB%8B-%E6%9D%A5%E8%87%AAwepon%E7%9A%84%E5%88%86%E4%BA%AB/)有简单的介绍。

#数据初步处理

``` python
    # -*- coding:utf-8 -*-
    __author__ = 'boredbird'
    import os
    import pandas as pd
    import woe.config as config
    import woe.feature_process as fp
    import woe.eval as eval
    import numpy as np
    import copy
    
    '''
    导入数据集与配置文件
    '''
    config_path = 'E:\\Code\\ScoreCard\\config\\config_whitelist_ext_pos.csv'
    data_path = 'E:\\ScoreCard\\rawdata\\whitelist\\pos_model_var_tbl_train_20160206.csv'
    cfg = config.config()
    cfg.load_file(config_path,data_path)
    
	'''
    填充空值
    '''
    for var in cfg.bin_var_list:
    # fill null
    cfg.dataset_train.loc[cfg.dataset_train[var].isnull(), (var)] = -1
    
    # change feature dtypes
    fp.change_feature_dtype(cfg.dataset_train, cfg.variable_type)
    
    rst = []
    
    columns = ['cus_id']
    columns.extend(cfg.candidate_var_list)
    columns.append('target')
    
    dataset_train = cfg.dataset_train[columns]
    
    '''
    删除不用的变量，导出数据集，减少内存占用
    '''
    dataset_train.to_csv('E:\\ScoreCard\\pos_model_var_eliminated_train_20160206.csv')
    '''
    重新导入数据集
    并指定变量类型
    '''
    config_path = 'E:\\Code\\ScoreCard\\config\\config_whitelist_ext_pos.csv'
    data_path = 'E:\\ScoreCard\\pos_model_var_eliminated_train_20160206.csv'
    cfg = config.config()
    cfg.load_file(config_path,data_path)
    
    for var in [tmp for tmp in cfg.bin_var_list if tmp in list(cfg.dataset_train.columns)]:
    	# fill null
    	cfg.dataset_train.loc[cfg.dataset_train[var].isnull(), (var)] = -1

    # change feature dtypes
    fp.change_feature_dtype(cfg.dataset_train, cfg.variable_type)
    
    rst = []
    
    # process woe transformation of continuous variables
    for var in [tmp for tmp in cfg.bin_var_list if tmp in list(cfg.dataset_train.columns)]:
    	rst.append(fp.proc_woe_continuous(cfg.dataset_train,var,cfg.global_bt,cfg.global_gt,cfg.min_sample,alpha=0.05))
    
    
    '''
    保存rst至文件
	'''
    import pickle
    output = open('E:\\Code\\ScoreCard\\whitelist_ext_civ_list.pkl', 'wb')
    pickle.dump(rst,output)
    output.close()
    
	'''
    格式化输出feature_detail，查看每个变量的iV值
    '''
    feature_detail = eval.eval_feature_detail(rst,'E:\\Code\\ScoreCard\\whitelist_ext_feature_detail.csv')
```    

#Woe 转换  

``` python
  
    '''
    Woe Transformation
    '''
    '''
    加载用于存储分割点信息的列表rst
    '''
    import pickle
    output = open('E:\\Code\\ScoreCard\\whitelist_ext_civ_list.pkl', 'rb')
    rst = pickle.load(output)
    output.close()

    '''
    FILL NULL
    因为在生成rst之前做了空值填充处理，
    所以在利用rst进行woe转换之前，也要分别对连续变量和离散变量做同样的空值填充。
    '''
    for var in [tmp for tmp in cfg.bin_var_list if tmp in list(cfg.dataset_train.columns)]:
    	# fill null
    	cfg.dataset_train.loc[cfg.dataset_train[var].isnull(), (var)] = -1
    
    for var in [tmp for tmp in cfg.discrete_var_list if tmp in list(cfg.dataset_train.columns)]:
    	# fill null
    	cfg.dataset_train.loc[cfg.dataset_train[var].isnull(), (var)] = 'missing'
    
    #Training dataset Woe Transformation
    for r in rst:
    	cfg.dataset_train[r.var_name] = fp.woe_trans(cfg.dataset_train[r.var_name],r)
    
    cfg.dataset_train.to_csv('E:\\ScoreCard\\pos_model_woe_transformated_train_20160206.csv')
    
    
    '''
    Validation Dataset Transformation
    '''
    #load dataset and eliminate variables
    dataset_validation = pd.read_csv('E:\\ScoreCard\\rawdata\\whitelist\\pos_model_var_tbl_validation_20160806.csv')
    var_exists_list = [rst[i].var_name for i in range(len(rst))]
    var_exists_list.extend(['cus_id','target',])
    columns_to_drop = [var for var in dataset_validation.columns if var not in var_exists_list]
    dataset_validation = dataset_validation.drop(columns_to_drop,axis=1)
    
    #change variable dtypes before woe transformation
    for var in [tmp for tmp in cfg.bin_var_list if tmp in list(dataset_validation.columns)]:
    	# fill null
    	dataset_validation.loc[dataset_validation[var].isnull(), (var)] = -1
    
    for var in [tmp for tmp in cfg.discrete_var_list if tmp in list(dataset_validation.columns)]:
    	# fill null
    	dataset_validation.loc[dataset_validation[var].isnull(), (var)] = 'missing'
    
    #Validation dataset Woe Transformation
    for r in rst:
		if r.var_name in dataset_validation.columns:
    		dataset_validation[r.var_name] = woe_trans(dataset_validation[r.var_name],r)
    
    dataset_validation.to_csv('E:\\ScoreCard\\pos_model_woe_transformated_validation_20160806.csv')
```    
    
#跑Logit Regression  

基于woe替换后的变量，删除iV值比较低的（删除了iv小于0.01的变量），调用statsmodels跑逻辑回归。

``` python
    import os
    import pandas as pd
    import woe.config as config
    import woe.feature_process as fp
    import woe.eval as eval
    import numpy as np
    
    
    dataset_train = pd.read_csv('E:\\ScoreCard\\pos_model_woe_transformated_train_20160206_new.csv')
    cfg = pd.read_csv('E:\\Code\\ScoreCard\\config\\config_whitelist_ext_pos.csv')
    candidate_var_list = cfg[cfg['is_modelfeature'] == 1]['var_name']
    
    import numpy as np
    from sklearn.model_selection import train_test_split
    
    X = dataset_train[candidate_var_list]
    y = dataset_train['target']
    
    X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=32)
    
    import statsmodels.api as sm
    logit_mod = sm.Logit(y_train,X_train)
    logit_res = logit_mod.fit(disp=0)
    # print('Parameters: ', logit_res.params)
    print logit_res.summary()  
```
  
![](https://i.imgur.com/6WYDulm.png)  

由上表可以看出当前这个模型存在两个问题：

1、存在变量系数显著性检验p值不通过的变量；

2、存在coef系数为负的情况，本身经过了woe转换后的变量的woe值与LR的概率值是正相关关系，系数应该为正，这种情况应该是变量之间的多重共线性导致的。

#模型评价，K-S

``` python

    from scipy.stats import ks_2samp
    get_ks = lambda y_pred,y_true: ks_2samp(y_pred[y_true==1], y_pred[y_true!=1]).statistic
    proba = logit_res.predict(X_train)
    get_ks(proba,y_train)
    # 0.35121344450518605
    
    proba = logit_res.predict(X_test)
    get_ks(proba,y_test)
    # 0.34393694879059489
    
    proba = logit_res.predict(dataset_validation[features_list])
    get_ks(proba,dataset_validation['target'])
    # 0.35956755211806057 
```