---
title: 逻辑回归评分卡调优（三）之剔除噪声
date: 2017-10-04 13:49:12 
categories: "机器学习" 
tags: 
     - 评分卡
     - 逻辑回归
description: 逻辑回归评分卡调优（三）之剔除噪声
toc: true
---
在[上回](https://boredbird.github.io/2017/10/04/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%84%E5%88%86%E5%8D%A1%E8%B0%83%E4%BC%98%EF%BC%88%E4%BA%8C%EF%BC%89%E4%B9%8B%E6%AD%A3%E5%88%99%E5%8C%96/)的基础上，我们可以看到[正则化](https://boredbird.github.io/2017/10/04/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%84%E5%88%86%E5%8D%A1%E8%B0%83%E4%BC%98%EF%BC%88%E4%BA%8C%EF%BC%89%E4%B9%8B%E6%AD%A3%E5%88%99%E5%8C%96/)带来了模型效果的提升。此时，在对建模宽表的加工过程检查发现，有一部分用户在特征加工时间窗口observe_date之前没有表现期，这部分的用户放在样本中其实是噪声，我们将之剔除，重新[woe](https://boredbird.github.io/2017/10/04/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%84%E5%88%86%E5%8D%A1%E8%B0%83%E4%BC%98%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%9D%E6%8E%A2/)转换，然后再入模查看效果。

首先，搜索最优正则化参数c：

``` python
    __author__ = 'boredbird'
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    from datetime import datetime
    from sklearn.model_selection import train_test_split
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import l1_min_c
    from scipy.stats import ks_2samp
    import woe.config as config
    import woe.feature_process as fp
    import woe.eval as eval
    
    get_ks = lambda y_pred,y_true: ks_2samp(y_pred[y_true==1], y_pred[y_true!=1]).statistic
    
    dataset_train = pd.read_csv('E:\\ScoreCard\\pos_train_20160406_agr_woe_trans.csv')
    cfg = pd.read_csv('E:\\Code\\ScoreCard\\config\\config_whitelist_ext_pos.csv')
    candidate_var_list = cfg[cfg['is_modelfeature'] == 1]['var_name']
    
    X = dataset_train[candidate_var_list]
    y = dataset_train['target']
    
    X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=32)
    
    # init a LogisticRegression model
    clf_l1_LR = LogisticRegression(C=0.1, penalty='l1', tol=0.01)
    cs = l1_min_c(X_train, y_train, loss='log') * np.logspace(0, 3)
    
    
    print("Computing regularization path ...")
    start = datetime.now()
    print start
    coefs_ = []
    ks = []
    for c in cs:
    clf_l1_LR.set_params(C=c)
    clf_l1_LR.fit(X_train, y_train)
    coefs_.append(clf_l1_LR.coef_.ravel().copy())
    
    proba = clf_l1_LR.predict_proba(X_train)[:,1]
    ks.append(get_ks(proba,y_train))
    
    end = datetime.now()
    print end
    print("This took ", end - start)
    
    coef_cv_df = pd.DataFrame(coefs_,columns=X_train.columns)
    coef_cv_df.to_csv('E:\\Code\\ScoreCard\\agr_coef_cv_df.csv')
    
    coefs_ = np.array(coefs_)
    
    fig1 = plt.figure('fig1')
    plt.plot(np.log10(cs), coefs_)
    ymin, ymax = plt.ylim()
    plt.xlabel('log(C)')
    plt.ylabel('Coefficients')
    plt.title('Logistic Regression Path')
    plt.axis('tight')
    plt.show()
    
    fig2 = plt.figure('fig2')
    plt.plot(np.log10(cs), ks)
    plt.xlabel('log(C)')
    plt.ylabel('ks score')
    plt.title('Logistic Regression Performance')
    plt.axis('tight')
    plt.show()
    
    fig2.show()
    fig1.show()
    
    print ks
    print cs
```    

![](https://i.imgur.com/812KAjt.png)
![](https://i.imgur.com/dAO4rdb.png)

然后，将最优正则化参数c代入，训练模型与预测：

``` python
    c = 0.00211473526246312
    clf_l1_LR = LogisticRegression(C=c, penalty='l1', tol=0.01)
    
	'''
	预测并查看模型效果
	'''
    clf_l1_LR.fit(X_train, y_train)
    proba = clf_l1_LR.predict_proba(X_train)[:,1]
    get_ks(proba,y_train)
    # 0.42519514636341194
    
    proba = clf_l1_LR.predict_proba(X_test)[:,1]
    get_ks(proba,y_test)
    # 0.42014866529356498
    
    dataset_validation = pd.read_csv('E:\\ScoreCard\\pos_validation_20160806_agr_woe_trans.csv')
    # fill null
    for var in candidate_var_list:
    if dataset_validation[var].isnull().sum()>0:
    dataset_validation.loc[dataset_validation[var].isnull(), (var)] = dataset_validation[var].mean()
    
    # prediction
    proba = clf_l1_LR.predict_proba(dataset_validation[candidate_var_list])[:,1]
    get_ks(proba,dataset_validation['target'])
    # 0.42007842928689282
```

可以看出，剔除一些噪声样本之后模型的效果有很大的提升，而且此时，训练集的效果与同时期验证，跨时期验证的效果都很接近，可以认为没有发生过拟合。