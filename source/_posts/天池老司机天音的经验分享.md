---
title: 天池老司机天音的经验分享
date: 2017-10-02 16:47:02 
categories: "机器学习" 
tags: 
     - 特征工程
     - FM
     - 模型融合
description: 天池老司机天音的经验分享
---
化繁为简，各个突破
# 一、数据处理 25%
## 1.1 缺失值填充
某些场景中缺失值也是一个重要特征，如金融信贷，资料完善度不高的用户是潜在的违约对象
* 数值型：均值，中位数
* 类别型：众数
* 通过关联信息补全
## 1.2 数据清洗
* 剔除缺失值比率大的字段
* 离群点剔除
## 1.3 数据处理
### 1.3.1 异常数据的处理
* log平滑
* 局部加权
### 1.3.2 数据划分，样本构造
* 增：增加样本，滑窗采样
* 减：去掉异常样本，可以借助模型判断
* 采样：效率和效果的平衡
* 根据需求构建可靠的验证集

注：线上线下Label窗口大小要一致；
滑窗是为了增加样本量，一般把多个窗口的数据集合在一起训练；
各窗口构成的数据集Label Window无重叠，特征窗口可以重叠；

![](https://i.imgur.com/Rotp1qh.png)
### 1.3.3 噪声样本剔除

用一个树模型去训练你的数据，然后用得到的模型去预测数据，同一个叶子节点下偏离叶子节点均值最大的认为它是一个噪声，然后对它的差值进行排序取出前top多少个，把它去掉，然后重新训练一个比较干净的模型

![](https://i.imgur.com/x73Fccz.png)

# 二、特征工程 50%
特征没做好，参数调到老
## 2.1 特征提取
结合具体的业务场景思考问题
* 特征统计：key拆分，组合（按照提供的数据集粒度，不同的维度去交叉组合出更多的指标）
* 时间窗口统计：3/5/7/15/30

![](https://i.imgur.com/VsnzLxO.png)

## 2.2 特征处理
* 归一化（加快训练速度并且更可能达到最优解，线性模型，对数值大小敏感的模型）
* onehot编码（增加哑变量）
* 排序

![](https://i.imgur.com/XA0iZiX.png)

## 2.3 特征选择
* 计算特征与标签相关度（按照相关性大小排序筛选特征）
* LR+L1正则
* 树模型对特征打分（用的最多的是XGBoost，RF去对特征打分，然后筛选重要的变量再放到线性模型里面）
## 2.4 特征组合
* 任意两两组合：维度大
* 特征选择再组合
![](https://i.imgur.com/ljfajAc.png)
* GBDT+LR（GBDT每棵树从根节点到叶子节点的路径是一种最优组合）
![](https://i.imgur.com/6GYh4FX.png)


# 三、模型设计 20%
## 3.1 分类-回归问题
* Xgboost：速度快，效果好
* GBDT：拟合能力强，有过拟合风险
* RF：不容易过拟合
* LR：对稀疏特征效果较好；常用来做stacker
## 3.2 Factorization Machine
![](https://i.imgur.com/joZrTya.png)
![](https://i.imgur.com/EZ4UBYE.png)
## 3.3 基于统计的方法（规则）
![](https://i.imgur.com/GKExOPP.png)
## 3.4 时序问题
* 回归类模型
* 规则函数
![](https://i.imgur.com/yZHle8t.png)
## 3.5 规则函数
![](https://i.imgur.com/Sz6n3Q6.png)

# 四、模型融合 5%
![](https://i.imgur.com/t12qj2u.png)
![](https://i.imgur.com/9nMKhTt.png)
