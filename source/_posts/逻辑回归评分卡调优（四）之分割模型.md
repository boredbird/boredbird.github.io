---
title: 逻辑回归评分卡调优（四）之分割模型
date: 2017-10-06 10:33:12 
categories: "机器学习" 
tags: 
     - 评分卡
     - 逻辑回归
description: 逻辑回归评分卡调优（四）之分割模型
---
在[上回](https://boredbird.github.io/2017/10/04/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%84%E5%88%86%E5%8D%A1%E8%B0%83%E4%BC%98%EF%BC%88%E4%B8%89%EF%BC%89%E4%B9%8B%E5%89%94%E9%99%A4%E5%99%AA%E5%A3%B0/)的基础上，我们可以看到根据业务理解[剔除噪声](https://boredbird.github.io/2017/10/04/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E8%AF%84%E5%88%86%E5%8D%A1%E8%B0%83%E4%BC%98%EF%BC%88%E4%B8%89%EF%BC%89%E4%B9%8B%E5%89%94%E9%99%A4%E5%99%AA%E5%A3%B0/)样本带来了模型效果的提升。同时也感受到了“与此相关”变量的重要，在这个字段上不同取值的客户所对应的入模特征分布也许有很大差异，于是我尝试了根据这个字段分割建模，期望能达到提升的效果。


# 按条件分割数据集：

* agr_dd1 + agr_dd2 + agr_dd3 + agr_dd4 == 1
* agr_dd1 + agr_dd2 + agr_dd3 + agr_dd4 == 2
* agr_dd1 + agr_dd2 + agr_dd3 + agr_dd4 == 3
* agr_dd1 + agr_dd2 + agr_dd3 + agr_dd4 >= 4

	
# 在分割出的4个训练集上分布训练WOE转换，然后对测试集进行对应的WOE转换

    __author__ = 'boredbird'
    import pandas as pd
    import woe.config as config
    import woe.feature_process as fp
    import woe.eval as eval
    import numpy as np
    import pickle
    import matplotlib.pyplot as plt
    from datetime import datetime
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import l1_min_c
    from scipy.stats import ks_2samp
    
    print '*************************************A****************************************************************'
    dataset = pd.read_csv('E:\\ScoreCard\\pos_train_20160406_agr.csv')
    dataset_dd1 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 1,:]
    dataset_dd2 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 2,:]
    dataset_dd3 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 3,:]
    dataset_dd4 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] >= 4,:]
    print '*************************************B****************************************************************'
    dataset_dd1.to_csv('E:\\ScoreCard\\pos_train_20160406_agr_dd1.csv')
    dataset_dd2.to_csv('E:\\ScoreCard\\pos_train_20160406_agr_dd2.csv')
    dataset_dd3.to_csv('E:\\ScoreCard\\pos_train_20160406_agr_dd3.csv')
    dataset_dd4.to_csv('E:\\ScoreCard\\pos_train_20160406_agr_dd4.csv')
    print '*************************************C****************************************************************'
    dataset = pd.read_csv('E:\\ScoreCard\\pos_test_20160406_agr.csv')
    dataset_dd1 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 1,:]
    dataset_dd2 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 2,:]
    dataset_dd3 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 3,:]
    dataset_dd4 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] >= 4,:]
    print '*************************************D****************************************************************'
    dataset_dd1.to_csv('E:\\ScoreCard\\pos_test_20160406_agr_dd1.csv')
    dataset_dd2.to_csv('E:\\ScoreCard\\pos_test_20160406_agr_dd2.csv')
    dataset_dd3.to_csv('E:\\ScoreCard\\pos_test_20160406_agr_dd3.csv')
    dataset_dd4.to_csv('E:\\ScoreCard\\pos_test_20160406_agr_dd4.csv')
    print '*************************************E****************************************************************'
    dataset = pd.read_csv('E:\\ScoreCard\\pos_model_var_tbl_validation_20160806_agr.csv')
    dataset_dd1 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 1,:]
    dataset_dd2 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 2,:]
    dataset_dd3 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] == 3,:]
    dataset_dd4 = dataset.loc[dataset['agr_dd1']+dataset['agr_dd2']+dataset['agr_dd3']+dataset['agr_dd4'] >= 4,:]
    print '*************************************F****************************************************************'
    dataset_dd1.to_csv('E:\\ScoreCard\\pos_validation_20160806_agr_dd1.csv')
    dataset_dd2.to_csv('E:\\ScoreCard\\pos_validation_20160806_agr_dd2.csv')
    dataset_dd3.to_csv('E:\\ScoreCard\\pos_validation_20160806_agr_dd3.csv')
    dataset_dd4.to_csv('E:\\ScoreCard\\pos_validation_20160806_agr_dd4.csv')
    
    # 'E:\\Code\\ScoreCard\\whitelist_ext_civ_list_alpha.pkl'
    # 'E:\\Code\\ScoreCard\\whitelist_ext_feature_detail_agr.csv'
    
    def process_train_woe(infile_path=None,outfile_path=None,rst_path=None):
    config_path = 'E:\\Code\\ScoreCard\\config\\config_whitelist_ext_pos.csv'
    data_path = infile_path
    cfg = config.config()
    cfg.load_file(config_path,data_path)
    
    for var in [tmp for tmp in cfg.bin_var_list if tmp in list(cfg.dataset_train.columns)]:
    # fill null
    cfg.dataset_train.loc[cfg.dataset_train[var].isnull(), (var)] = -1
    
    # change feature dtypes
    fp.change_feature_dtype(cfg.dataset_train, cfg.variable_type)
    rst = []
    
    # process woe transformation of continuous variables
    print 'cfg.global_bt',cfg.global_bt
    print 'cfg.global_gt', cfg.global_gt
    
    for var in [tmp for tmp in cfg.bin_var_list if tmp in list(cfg.dataset_train.columns)]:
    rst.append(fp.proc_woe_continuous(cfg.dataset_train,var,cfg.global_bt,cfg.global_gt,cfg.min_sample,alpha=0.05))
    
    # process woe transformation of discrete variables
    for var in [tmp for tmp in cfg.discrete_var_list if tmp in list(cfg.dataset_train.columns)]:
    # fill null
    cfg.dataset_train.loc[cfg.dataset_train[var].isnull(), (var)] = 'missing'
    rst.append(fp.proc_woe_discrete(cfg.dataset_train,var,cfg.global_bt,cfg.global_gt,cfg.min_sample,alpha=0.05))
    
    eval.eval_feature_detail(rst, outfile_path)
    
    output = open(rst_path, 'wb')
    pickle.dump(rst,output)
    output.close()
    
    print '*************************************G****************************************************************'
    process_train_woe(infile_path='E:\\ScoreCard\\pos_train_20160406_agr_dd1.csv'
      ,outfile_path='E:\\Code\\ScoreCard\\whitelist_ext_feature_detail_agr_dd1.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd1.pkl')
    print '*************************************H****************************************************************'
    process_train_woe(infile_path='E:\\ScoreCard\\pos_train_20160406_agr_dd2.csv'
      ,outfile_path='E:\\Code\\ScoreCard\\whitelist_ext_feature_detail_agr_dd2.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd2.pkl')
    print '*************************************I****************************************************************'
    process_train_woe(infile_path='E:\\ScoreCard\\pos_train_20160406_agr_dd3.csv'
      ,outfile_path='E:\\Code\\ScoreCard\\whitelist_ext_feature_detail_agr_dd3.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd3.pkl')
    print '*************************************J****************************************************************'
    process_train_woe(infile_path='E:\\ScoreCard\\pos_train_20160406_agr_dd4.csv'
      ,outfile_path='E:\\Code\\ScoreCard\\whitelist_ext_feature_detail_agr_dd4.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd4.pkl')
    
    
    def process_woe_trans(in_data_path=None,rst_path=None,out_path=None):
    config_path = 'E:\\Code\\ScoreCard\\config\\config_whitelist_ext_pos.csv'
    data_path = in_data_path
    cfg = config.config()
    cfg.load_file(config_path, data_path)
    
    fp.change_feature_dtype(cfg.dataset_train, cfg.variable_type)
    for var in [tmp for tmp in cfg.bin_var_list if tmp in list(cfg.dataset_train.columns)]:
    # fill null
    cfg.dataset_train.loc[cfg.dataset_train[var].isnull(), (var)] = -1
    
    for var in [tmp for tmp in cfg.discrete_var_list if tmp in list(cfg.dataset_train.columns)]:
    # fill null
    cfg.dataset_train.loc[cfg.dataset_train[var].isnull(), (var)] = 'missing'
    
    output = open(rst_path, 'rb')
    rst = pickle.load(output)
    output.close()
    
    # Training dataset Woe Transformation
    for r in rst:
    cfg.dataset_train[r.var_name] = fp.woe_trans(cfg.dataset_train[r.var_name], r)
    
    cfg.dataset_train.to_csv(out_path)
    
    print '*************************************K****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_test_20160406_agr_dd1.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd1.pkl'
      ,out_path='E:\\ScoreCard\\pos_test_20160406_agr_dd1_woe_trans.csv')
    print '*************************************L****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_test_20160406_agr_dd2.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd2.pkl'
      ,out_path='E:\\ScoreCard\\pos_test_20160406_agr_dd2_woe_trans.csv')
    print '*************************************M****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_test_20160406_agr_dd3.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd3.pkl'
      ,out_path='E:\\ScoreCard\\pos_test_20160406_agr_dd3_woe_trans.csv')
    print '*************************************N****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_test_20160406_agr_dd4.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd4.pkl'
      ,out_path='E:\\ScoreCard\\pos_test_20160406_agr_dd4_woe_trans.csv')
    print '*************************************O****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd1.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd1.pkl'
      ,out_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd1_woe_trans.csv')
    print '*************************************P****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd2.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd2.pkl'
      ,out_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd2_woe_trans.csv')
    print '*************************************Q****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd3.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd3.pkl'
      ,out_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd3_woe_trans.csv')
    print '*************************************R****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd4.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd4.pkl'
      ,out_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd4_woe_trans.csv')
    
    
    print '*************************************K****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_train_20160406_agr_dd1.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd1.pkl'
      ,out_path='E:\\ScoreCard\\pos_train_20160406_agr_dd1_woe_trans.csv')
    print '*************************************L****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_train_20160406_agr_dd2.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd2.pkl'
      ,out_path='E:\\ScoreCard\\pos_train_20160406_agr_dd2_woe_trans.csv')
    print '*************************************M****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_train_20160406_agr_dd3.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd3.pkl'
      ,out_path='E:\\ScoreCard\\pos_train_20160406_agr_dd3_woe_trans.csv')
    print '*************************************N****************************************************************'
    process_woe_trans(in_data_path='E:\\ScoreCard\\pos_train_20160406_agr_dd4.csv'
      ,rst_path='E:\\Code\\ScoreCard\\whitelist_ext_civ_list_dd4.pkl'
      ,out_path='E:\\ScoreCard\\pos_train_20160406_agr_dd4_woe_trans.csv')
    
    
    
    """
    Training Model
    """
    get_ks = lambda y_pred,y_true: ks_2samp(y_pred[y_true==1], y_pred[y_true!=1]).statistic
    
    def train_model(infile,outfile,fig1,fig2):
    dataset_train = pd.read_csv(infile)
    cfg = pd.read_csv('E:\\Code\\ScoreCard\\config\\config_whitelist_ext_pos.csv')
    candidate_var_list = cfg[cfg['is_modelfeature'] == 1]['var_name']
    
    X_train = dataset_train[candidate_var_list]
    y_train = dataset_train['target']
    
    # init a LogisticRegression model
    clf_l1_LR = LogisticRegression(C=0.1, penalty='l1', tol=0.01)
    cs = l1_min_c(X_train, y_train, loss='log') * np.logspace(0, 3)
    
    print("Computing regularization path ...")
    start = datetime.now()
    print start
    coefs_ = []
    ks = []
    for c in cs:
    clf_l1_LR.set_params(C=c)
    clf_l1_LR.fit(X_train, y_train)
    coefs_.append(clf_l1_LR.coef_.ravel().copy())
    
    proba = clf_l1_LR.predict_proba(X_train)[:,1]
    ks.append(get_ks(proba,y_train))
    
    end = datetime.now()
    print end
    print("This took ", end - start)
    
    coef_cv_df = pd.DataFrame(coefs_,columns=X_train.columns)
    coef_cv_df['ks'] = ks
    coef_cv_df['cs'] = cs
    coef_cv_df.to_csv(outfile)
    
    coefs_ = np.array(coefs_)
    
    plt.figure()
    plt.plot(np.log10(cs), coefs_)
    ymin, ymax = plt.ylim()
    plt.xlabel('log(C)')
    plt.ylabel('Coefficients')
    plt.title('Logistic Regression Path')
    plt.axis('tight')
    plt.savefig(fig1)
    plt.close()
    
    plt.figure()
    plt.plot(np.log10(cs), ks)
    plt.xlabel('log(C)')
    plt.ylabel('ks score')
    plt.title('Logistic Regression Performance')
    plt.axis('tight')
    plt.savefig(fig2)
    plt.close()
    
    train_model(infile='E:\\ScoreCard\\pos_train_20160406_agr_dd1_woe_trans.csv'
    ,outfile='E:\\ScoreCard\\coef_cv_df_agr_dd1.csv'
    ,fig1='E:\\ScoreCard\\LR_Path_cv_agr_dd1.png'
    ,fig2='E:\\ScoreCard\\LR_Performance_cv_agr_dd1.png')
    
    train_model(infile='E:\\ScoreCard\\pos_train_20160406_agr_dd2_woe_trans.csv'
    ,outfile='E:\\ScoreCard\\coef_cv_df_agr_dd2.csv'
    ,fig1='E:\\ScoreCard\\LR_Path_cv_agr_dd2.png'
    ,fig2='E:\\ScoreCard\\LR_Performance_cv_agr_dd2.png')
    
    train_model(infile='E:\\ScoreCard\\pos_train_20160406_agr_dd3_woe_trans.csv'
    ,outfile='E:\\ScoreCard\\coef_cv_df_agr_dd3.csv'
    ,fig1='E:\\ScoreCard\\LR_Path_cv_agr_dd3.png'
    ,fig2='E:\\ScoreCard\\LR_Performance_cv_agr_dd3.png')
    
    train_model(infile='E:\\ScoreCard\\pos_train_20160406_agr_dd4_woe_trans.csv'
    ,outfile='E:\\ScoreCard\\coef_cv_df_agr_dd4.csv'
    ,fig1='E:\\ScoreCard\\LR_Path_cv_agr_dd4.png'
    ,fig2='E:\\ScoreCard\\LR_Performance_cv_agr_dd4.png')
      
    """
    Model Performance
    """
    def predict_model(train_file,test_file,dataset_validation_path,c):
    print '*********************************************************'
    cfg = pd.read_csv('E:\\Code\\ScoreCard\\config\\config_whitelist_ext_pos.csv')
    candidate_var_list = cfg[cfg['is_modelfeature'] == 1]['var_name']
    clf_l1_LR = LogisticRegression(C=c, penalty='l1', tol=0.01,class_weight='balanced')
    
    dataset_train = pd.read_csv(train_file)
    dataset_test = pd.read_csv(test_file)
    dataset_validation = pd.read_csv(dataset_validation_path)
    # fill null
    for var in candidate_var_list:
    if dataset_validation[var].isnull().sum()>0:
    dataset_validation.loc[dataset_validation[var].isnull(), (var)] = dataset_validation[var].mean()
    
    if dataset_test[var].isnull().sum()>0:
    dataset_test.loc[dataset_test[var].isnull(), (var)] = dataset_test[var].mean()
    
    X_train = dataset_train[candidate_var_list]
    y_train = dataset_train['target']
    
    X_test = dataset_test[candidate_var_list]
    y_test = dataset_test['target']
    
    clf_l1_LR.fit(X_train, y_train)
    proba = clf_l1_LR.predict_proba(X_train)[:,1]
    print get_ks(proba,y_train)
    
    proba = clf_l1_LR.predict_proba(X_test)[:,1]
    print get_ks(proba,y_test)
    
    # prediction
    proba = clf_l1_LR.predict_proba(dataset_validation[candidate_var_list])[:,1]
    print get_ks(proba,dataset_validation['target'])
     
    predict_model(train_file='E:\\ScoreCard\\pos_train_20160406_agr_dd1_woe_trans.csv'
      ,test_file='E:\\ScoreCard\\pos_test_20160406_agr_dd1_woe_trans.csv'
      ,dataset_validation_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd1_woe_trans.csv'
      ,c=0.00948742173925)
    '''
    agr_dd1:
    0.391337297417
    0.401760434721
    0.41978303981
    '''
    
    predict_model(train_file='E:\\ScoreCard\\pos_train_20160406_agr_dd2_woe_trans.csv'
      ,test_file='E:\\ScoreCard\\pos_test_20160406_agr_dd2_woe_trans.csv'
      ,dataset_validation_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd2_woe_trans.csv'
      ,c=0.00949207179031)
    '''
    agr_dd2:
    0.42881515259
    0.425330615971
    0.423628758103
    '''

    predict_model(train_file='E:\\ScoreCard\\pos_train_20160406_agr_dd3_woe_trans.csv'
      ,test_file='E:\\ScoreCard\\pos_test_20160406_agr_dd3_woe_trans.csv'
      ,dataset_validation_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd3_woe_trans.csv'
      ,c=0.0063130606165)
    '''
    agr_dd3:
    0.444853052712
    0.442965593278
    0.429972957194
    '''

    predict_model(train_file='E:\\ScoreCard\\pos_train_20160406_agr_dd4_woe_trans.csv'
      ,test_file='E:\\ScoreCard\\pos_test_20160406_agr_dd4_woe_trans.csv'
      ,dataset_validation_path='E:\\ScoreCard\\pos_validation_20160806_agr_dd4_woe_trans.csv'
      ,c=0.00479980706543)
    '''
    agr_dd4:
    0.45628377635
    0.445146067293
    0.464371772806
    '''

# 结论
由切分成4个数据集分别的ks表现来看，分割后的模型表现差异比较明显，并且agr_dd1，agr_dd2，agr_dd3，agr_dd4的ks逐渐提升，这也不难寻求业务理解。可见，在这个字段上分割模型是有意义。  

逻辑回归是线性的且单一的分类器，即使我们把这4个数据集增加一个‘A’,'B','C','D'的字段标识，然后合并为一个数据集，也不能够达到分割的效果。分割模型相对于只是分割数据集会进一步增强模型的表现能力。

**分割数据集**

![](https://i.imgur.com/HFzIexW.png)

**分割模型**

![](https://i.imgur.com/59fOnql.png)